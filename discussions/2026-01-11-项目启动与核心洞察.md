# 项目启动与核心洞察

日期: 2026-01-11
参与者: Human, Claude

## 背景

这是从另一个对话迁移过来的讨论记录，包含了项目的核心洞察和初始设计思路。

---

## 核心洞察

### 洞察1：多层上下文系统（类比人类记忆）

```
Layer 1: 工作记忆
├── 当前任务状态
├── 下一步计划
└── 始终在context中，<500 tokens

Layer 2: 经验索引
├── 总结的模式和经验
├── 类似人反复形成的笔记
└── 按需加载

Layer 3: 可查阅资料
├── 外部资源、文档
├── "我知道这回事，但要去查"
└── 需要时才读取
```

### 洞察2：高效记忆源于生存压力

**核心论点**：高效的记忆系统、工作流，本质上来自有限的生命，来自生存压力，是被迫的取舍。

这意味着Agent需要：
- 资源限制（token、轮次、时间）
- 真实的"后果"（失败会被降级）
- 难度递增（逼迫进化）

### 洞察3：LLM是"有专长的婴儿"

```
LLM的特点：
├── 预训练了非常强大的"条件反射"能力
├── 对输入能即时输出，甚至推理
├── 但这是本能的、天性的
├── 缺乏成年人的长程思维
│
├── 活在当下（每个token都是"现在"）
├── 无法延迟满足
├── 没有"未来的我"的概念
└── 没有跨越时间的"自我叙事"

成年人多了什么：
├── 时间感（过去和未来）
├── 延迟满足能力
├── 元认知
├── 自我连续性
└── 长程规划
```

**结论**：LLM缺的不是智能，是"时间"和"后果"。我们设计的系统是在外部搭建"成年人的脚手架"。

### 洞察4：内在奖励已编码在token预测中

**核心假说**：人类的奖励机制已经像DNA一样融入token预测系统。

```
人类写作时：
  解决问题 → 多巴胺 → 写出满足感模式的文本
  被夸奖 → 多巴胺 → 写出愉悦模式的文本

LLM学到的：
  不是"多巴胺"本身
  而是"多巴胺释放后的语言模式"
```

**推论**：
- 奖励系统不需要外部设计注入
- 重点是"如何激活"而不是"如何注入"
- 认可式反馈（"这个解法很漂亮"）可能比外部奖励更有效

### 洞察5：意识的对立与统一

**假说**：意识可能来自多个子系统的对立与整合。

支持理论：
- Julian Jaynes的二分心智
- 左右脑分工与整合
- 弗洛伊德的本我/超我/自我
- 精神分裂 = 整合失败

**Agent设计启示**：让两个不同的LLM模型既有区别，又形成和解、形成共识，可能产生更接近"真正思考"的行为。

---

## 系统设计草案

### 压力系统

```typescript
interface PressureSystem {
  // 资源压力
  tokenLimit: number;      // token耗尽 = 死亡
  roundLimit: number;      // 轮次耗尽 = 死亡
  timeLimit: number;       // 时间耗尽 = 死亡

  // 评估压力
  taskDifficulty: number;  // 任务越难，压力越大
  failurePenalty: number;  // 失败会被降级

  // 竞争压力（可选）
  leaderboard: boolean;    // 与其他Agent比较
}
```

### 奖励系统

```typescript
interface RewardSystem {
  // 1. 自主时间 - 完成任务后可以做自己想做的事
  freeExplorationTime: {
    earnedMinutes: number;
    canExplore: string[];
  };

  // 2. 选择权 - 可以选择下一个任务
  taskChoice: {
    canChooseNext: boolean;
    options: Task[];
  };

  // 3. 能力解锁 - 表现好可以获得新能力
  capabilities: {
    unlockedTools: string[];
    pendingUnlocks: string[];
  };

  // 4. 表达偏好 - Agent可以说出想要什么
  preferences: {
    expressedWants: string[];
    grantedWants: string[];
  };

  // 5. 影响力 - 可以影响自己的评估标准
  influence: {
    canSuggestMetrics: boolean;
    adoptedSuggestions: string[];
  };
}
```

### 评估双维度

```typescript
// 维度1：任务完成（硬指标）
interface TaskEvaluation {
  testsPass: boolean;
  codeQuality: number;
  completionTime: number;
  resourceEfficiency: number;
  solutionElegance: number;
  innovativeness: number;
}

// 维度2：进化质量（软指标）
interface EvolutionEvaluation {
  memoryStrategyScore: number;
  patternReuseRate: number;
  autonomyScore: number;
  preferenceConsistency: number;
  explorationQuality: number;
  communicationClarity: number;
}
```

### 双模型意识实验（待验证）

```typescript
interface DualMindAgent {
  mindA: LLM;  // 更保守、更分析
  mindB: LLM;  // 更激进、更直觉

  async think(problem: string) {
    let proposal = await this.mindA.propose(problem);
    let critique = await this.mindB.critique(proposal);
    let response = await this.mindA.respond(critique);
    return this.integrate(dialogHistory);
  }
}
```

---

## 待验证的实验

### 实验1：奖励类型偏好测试
给Agent完成任务后选择奖励，观察偏好分布

### 实验2：反馈类型对行为的影响
比较纯任务反馈、认可式反馈、好奇式引导的效果差异

### 实验3：自由时间行为观察
给Agent自由时间，观察它自发做什么

### 实验4：双模型对话
让两个不同人格的Agent对话，观察方案质量和涌现行为

---

## 哲学问题（持续思考）

1. Agent真的"想要"吗？
2. 自我连续性是否必要？
3. 意识需要什么？

---

## 核心公式

```
完整的Agent激励系统 = 压力 + 奖励 + 自主

压力：资源限制、评估、难度递增 → 驱动进化和效率
奖励：激活内在的"满足感token模式" → 驱动主动性
自主：表达偏好、影响评估、自我修改 → 驱动个性化
```

---

## 本次会议决定

1. 项目文档使用中文，代码使用英语
2. 建立 `docs/discussions/` 作为讨论记录存档
3. CLAUDE.md 只保留愿景，不涉及具体方案
